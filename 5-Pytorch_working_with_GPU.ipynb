{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRYL3Ry1bl4a"
      },
      "source": [
        "some part of this notebook are copied from Jose Marcial Portilla works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWC1pKKGNjFd"
      },
      "source": [
        "# What is CUDA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49HxoNm1NjFe"
      },
      "source": [
        "Most people confuse CUDA for a language or maybe an API. It is not.\n",
        "\n",
        "Itâ€™s more than that. CUDA is a parallel computing platform and programming model that makes using a GPU for general purpose computing simple and elegant. The developer still programs in the familiar C, C++, Fortran, or an ever expanding list of supported languages, and incorporates extensions of these languages in the form of a few basic keywords.\n",
        "\n",
        "These keywords let the developer express massive amounts of parallelism and direct the compiler to the portion of the application that maps to the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Om4zVWNjFg"
      },
      "source": [
        "# How do I know if I have CUDA available?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRE5bBjhNjFh",
        "outputId": "342c605d-5bdd-4684-e6bb-20da2d19c312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "# True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvXV2k-kNjFk",
        "outputId": "14ff2eb6-09d9-45e6-cff6-2c788d39f9d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Get Id of default device\n",
        "torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dFMChJNyNjFl",
        "outputId": "dab687f3-b2a6-453e-e731-6963114e7e40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0\n",
        "# torch.cuda.get_device_name(0) # Get name device with ID '0'\n",
        "torch.cuda.get_device_name(torch.cuda.current_device())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkiVDkeeNjFn",
        "outputId": "3360f79d-3d13-4418-cdec-b56b25c2594c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Returns the current GPU memory usage by \n",
        "# tensors in bytes for a given device\n",
        "torch.cuda.memory_allocated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnVL1qVlNjFn",
        "outputId": "d6a45999-6ec0-43e8-fab9-34152bc9ce61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:393: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Returns the current GPU memory managed by the\n",
        "# caching allocator in bytes for a given device\n",
        "torch.cuda.memory_cached()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRWAG4B4NjFo"
      },
      "source": [
        "# Using CUDA instead of CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2F5PeEcNjFo"
      },
      "outputs": [],
      "source": [
        "# CPU\n",
        "a = torch.tensor([1.,2.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfHPLFaeNjFq",
        "outputId": "78104271-8677-4b0c-f685-d37509ea71dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2.])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtrwFM7QNjFr",
        "outputId": "fb4db451-9d57-4d86-cb1a-46761be8f2dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUu0NDMwNjFr"
      },
      "outputs": [],
      "source": [
        "# GPU\n",
        "a = torch.tensor([1., 2.]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i6lY7S0NjFr",
        "outputId": "53da67da-1e63-4eca-95c3-995dad8a240b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvDG3pzyNjFs",
        "outputId": "b4781422-aa03-4941-aa85-dde82b87035c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.memory_allocated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezPdZ5dcNjFt"
      },
      "source": [
        "## Sending Models to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM55eBUSNjFu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ClLlTp4NjFu"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
        "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
        "        self.out = nn.Linear(h2, out_features)  # output layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQtSk4q_NjFv"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(32)\n",
        "model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWUseYs8ea7n",
        "outputId": "78781847-a030-47ae-a88c-74fde8042f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3757, -0.2279, -0.0859,  0.2857],\n",
            "        [-0.3870,  0.0793,  0.1481, -0.4771],\n",
            "        [ 0.0874, -0.1746,  0.4485,  0.0219],\n",
            "        [ 0.3782,  0.2254,  0.1929, -0.4741],\n",
            "        [ 0.4319, -0.4087,  0.2177,  0.2271],\n",
            "        [-0.0033,  0.4308, -0.1323, -0.2951],\n",
            "        [ 0.1646, -0.1114, -0.4213, -0.3553],\n",
            "        [-0.3191,  0.1440, -0.3496,  0.2280]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.3867, -0.2029,  0.2828,  0.0105,  0.3187, -0.0630, -0.3122,  0.3781],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.2174,  0.0821,  0.2015, -0.2559, -0.3214,  0.1976, -0.3494, -0.2639],\n",
            "        [ 0.1533, -0.1185,  0.2496, -0.0764,  0.0569, -0.1953,  0.0699, -0.3265],\n",
            "        [-0.2689, -0.2716,  0.0416, -0.0628,  0.3519,  0.0132,  0.3048, -0.2101],\n",
            "        [ 0.0877, -0.0607,  0.3204,  0.1180,  0.0254, -0.2260, -0.3002, -0.1128],\n",
            "        [ 0.1822, -0.1912, -0.1485, -0.3094,  0.3335,  0.3195, -0.2034,  0.0114],\n",
            "        [-0.0197,  0.0627, -0.2298, -0.2206, -0.0519, -0.2718,  0.0394, -0.1808],\n",
            "        [-0.2795, -0.0174, -0.1481,  0.1461,  0.2875, -0.2088, -0.1105, -0.0624],\n",
            "        [-0.3446, -0.3429,  0.1410, -0.0229, -0.1807,  0.3378, -0.3523,  0.3125],\n",
            "        [-0.3375, -0.2082,  0.1935, -0.0895, -0.1062, -0.2413,  0.1080,  0.2850]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1152,  0.3461, -0.2808, -0.2912, -0.2119, -0.0359,  0.0618,  0.0072,\n",
            "         0.0421], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.2155, -0.0865,  0.0273,  0.0950, -0.2244,  0.2267, -0.0257,  0.1240,\n",
            "          0.3012],\n",
            "        [ 0.1761,  0.1315, -0.1248, -0.2349,  0.1171,  0.2718,  0.1800,  0.0272,\n",
            "          0.2760],\n",
            "        [-0.1173, -0.1334, -0.1451, -0.1778, -0.0134, -0.3219,  0.2362, -0.3331,\n",
            "         -0.1583]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1337, -0.0185, -0.1372], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey1glCoJNjFv",
        "outputId": "e35563c8-a697-4099-ddc7-0c0e6d66fc2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# From the discussions here: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
        "next(model.parameters()).is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oagzMrXRNjFw"
      },
      "outputs": [],
      "source": [
        "gpumodel = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nUlTT3jNjFw",
        "outputId": "ae6ae77b-13d9-4c12-f769-551d0fecb6e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(gpumodel.parameters()).is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_0JjRysNjFx"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('../content/Data/iris.csv')\n",
        "# X = df.drop('target',axis=1).values\n",
        "# y = df['target'].values\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
        "\n",
        "# df = pd.read_csv('../content/Data/iris.csv')\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itiN7sa4NjFx"
      },
      "source": [
        "## Convert Tensors to .cuda() tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOFBSxLLNjFx",
        "outputId": "009382d9-3cba-4148-813b-2d82773b4a0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "X_train = torch.tensor(X_train).cuda()\n",
        "X_test = torch.tensor(X_test).cuda()\n",
        "y_train = torch.tensor(y_train).cuda()\n",
        "y_test = torch.tensor(y_test).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2R1rt8UNjFy"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm9UpETdNjFy"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wht7p-tcNjFy",
        "outputId": "e7233f79-7e77-449c-ed01-1bb616973db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  1  loss: 1.15071130\n",
            "epoch: 11  loss: 0.93773133\n",
            "epoch: 21  loss: 0.77982587\n",
            "epoch: 31  loss: 0.60994011\n",
            "epoch: 41  loss: 0.40079933\n",
            "epoch: 51  loss: 0.25436324\n",
            "epoch: 61  loss: 0.15053056\n",
            "epoch: 71  loss: 0.10086948\n",
            "epoch: 81  loss: 0.08128316\n",
            "epoch: 91  loss: 0.07231428\n",
            "TOTAL TRAINING TIME: 2.8728034496307373\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "epochs = 100\n",
        "losses = []\n",
        "start = time.time()\n",
        "for i in range(epochs):\n",
        "    i+=1\n",
        "    y_pred = gpumodel.forward(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    losses.append(loss)\n",
        "    \n",
        "    # a neat trick to save screen space:\n",
        "    if i%10 == 1:\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d8vayCOOp13"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "981a068c3610acb4413548f03f3bf99c774b8d3a92250b4c28a67fc7f96081b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
